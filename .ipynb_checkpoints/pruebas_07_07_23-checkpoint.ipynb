{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7f6a9f-7ce1-4e98-84f3-c32d2377b58e",
   "metadata": {},
   "source": [
    " los 3 modelos que mejor se ajustan a datos no linealmente separables son:\n",
    "\n",
    "1. Support Vector Machines (SVM): SVM es especialmente efectivo en la clasificación de datos no linealmente separables. Utiliza una función de kernel para mapear los datos a un espacio de mayor dimensión donde los datos pueden ser linealmente separables. Esto permite capturar relaciones no lineales entre las características y mejorar el rendimiento de la clasificación.\n",
    "\n",
    "2. Gaussian Processes: Los procesos gaussianos son útiles cuando los datos no se pueden modelar de manera lineal. Estos modelos no paramétricos son capaces de capturar relaciones no lineales y se basan en la estimación de la distribución de probabilidad conjunta de las variables. Pueden adaptarse a patrones complejos y proporcionar incertidumbre en las predicciones.\n",
    "\n",
    "3. Decision Trees: Los árboles de decisión son capaces de modelar relaciones no lineales entre las características y la variable objetivo. Estos modelos dividen recursivamente el espacio de características en regiones más pequeñas y realizan decisiones en función de reglas de partición. Pueden capturar patrones no lineales de manera efectiva y son especialmente útiles cuando las relaciones entre las características no son lineales.\n",
    "\n",
    "En resumen, SVM, Gaussian Processes y Decision Trees son modelos que se destacan en la clasificación de datos no linealmente separables debido a su capacidad para capturar relaciones no lineales y adaptarse a patrones complejos en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387fdc0d-ca18-4522-88f5-95e1bb249a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga completa\n"
     ]
    }
   ],
   "source": [
    "#Resumen\n",
    "\n",
    "# Librerias a utilizar, por defecto ya vienen instaladas en el entorno \"pip install git jupyterlab numpy pandas plotly \"\n",
    "# para mejor visualizacion de los df y manejo de estadisticas:\n",
    "# ! pip install pandasgui\n",
    "# ! pip install pandas-profiling\n",
    "# ! pip install seaborn\n",
    "# ! pip install scipy\n",
    "#! pip install optbinning\n",
    "#! pip install ortools == 9.4.1874\n",
    "#! pip install -U scikit-learn\n",
    "import os\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasgui import show\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import statsmodels.api as sm\n",
    "from optbinning import OptimalBinning\n",
    "from optbinning import BinningProcess\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score , recall_score, f1_score, make_scorer \n",
    "print(\"librerias cargadas correctamente\") \n",
    "\n",
    "class revisor_data_csv:\n",
    "    \"\"\"Clase para carga y revisión de archivos con formato .csv\n",
    "    Con esto podemos visualizar y manipular la data de forma controlada minimizando errores y\n",
    "    pudiendo posteriormente crar un pipeline del proceso ETL\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Constructor de la clase que recibe la ruta del archivo y carga el archivo\n",
    "        Se asume archivos .csv estándar, sep = \",\"\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        try:\n",
    "            # Se carga el df \n",
    "            self.mensaje(\"cargando\", self.file_path)\n",
    "            self.df = pd.read_csv(self.file_path)\n",
    "            self.mensaje(\"cargado\")\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "            \n",
    "    def mensaje(self, tipo, arg=None):\n",
    "        tipos_mensajes = {\"cargando\": f\"Cargando archivo {arg}\",\n",
    "                          \"cargado\": \"Carga completa\"}\n",
    "        if tipo in tipos_mensajes:\n",
    "            clear_output(wait=True)\n",
    "            print(tipos_mensajes[tipo])\n",
    "        else:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Tipo de mensaje no válido\")\n",
    "            print(f\"{list(tipos_mensajes.keys())}\")\n",
    "    \n",
    "    def analisis_nulos(self):\n",
    "        cuenta_nulos = self.df.isnull().sum()\n",
    "        cuenta_nulos = cuenta_nulos[cuenta_nulos != 0]\n",
    "        porcentaje_nulos = round((cuenta_nulos / self.df.shape[0]) * 100, 2)\n",
    "        return pd.DataFrame({\"cant_nulos\": cuenta_nulos, \"porcentaje_nulos\": porcentaje_nulos})\n",
    "\n",
    "    def nulos_EliminacionSimple(self, lista):\n",
    "        \"\"\"Se eliminarán las filas que contengan valores nulos en las columnas indicadas por la lista\"\"\"\n",
    "        try:\n",
    "            self.df = self.df.dropna(subset=lista)\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def nulos_MediaCondicional(self, variable, lista):\n",
    "        \"\"\"Se asignará a los valores nulos de la columna variable,\n",
    "        el valor promedio agrupando con las columnas indicadas por la lista\"\"\"\n",
    "        try:\n",
    "            self.df.loc[self.df[variable].isnull(), variable] = self.df.groupby(lista, as_index=False)[[variable]].transform('mean')\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def eliminar_por_condicion(self,columna,condicion):\n",
    "        \"\"\"Se eliminarán las filas que contengan valores 'condicion' en la columna indicadas por la lista\"\"\"\n",
    "        try:\n",
    "            self.df = self.df.drop(self.df[self.df[columna] == condicion].index)\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "#revision = revisor_data_csv(\"..\\\\datos_internos/20210513_Challenge_AA_MANANA.csv\")\n",
    "revision = revisor_data_csv(\"df_prueba_MANANA.csv\")\n",
    "\n",
    "# Eliminacion de valores nulos\n",
    "revision.nulos_EliminacionSimple(['MORAS', 'SEXO', 'ESTADOCIVIL', 'FECHANACIMIENTO', 'ANTIGUEDAD', 'EDAD'])\n",
    "revision.nulos_MediaCondicional('INGRESO',['ESTADO','EDAD','ESTADOCIVIL','SEXO'])\n",
    "revision.nulos_EliminacionSimple(['INGRESO'])\n",
    "revision.df['MORAS'] = revision.df['MORAS'].astype(int)\n",
    "revision.df['ANTIGUEDAD'] = revision.df['ANTIGUEDAD'].astype(int)\n",
    "revision.df['EDAD'] = revision.df['EDAD'].astype(int)\n",
    "revision.df['FECHANACIMIENTO'] = pd.to_datetime(revision.df['FECHANACIMIENTO']).dt.date\n",
    "revision.df['FECHANACIMIENTO'] = pd.to_datetime(revision.df['FECHANACIMIENTO'])\n",
    "revision.eliminar_por_condicion('ESTADOCIVIL',' ')\n",
    "\n",
    "revision.df = revision.df.drop(['CLIENTE'], axis=1)\n",
    "\n",
    "class preprocesamiento:\n",
    "    def __init__(self,revisor_data):\n",
    "        \"\"\"\n",
    "        Constructor de la clase recibe el objeto instanciado de la clase revisor_data_csv, \n",
    "        seria mejor usar un patron de diseño DataFrameSingleton pero esta division solo es \n",
    "        para fines demostrativos,en codigo final todos los metodos deben \n",
    "        pertenecer a una sola clase.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Se carga el df \n",
    "            self.revisor_data = revisor_data\n",
    "            self.df = self.revisor_data.df\n",
    "            self.matriz_correlacion = None\n",
    "            self.transformaciones = {}\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    #Este metodo esta repetido en la clase graficos, al final se debe mejorar el codigo ya sea uniendo todas las clases o usando herencias.\n",
    "    def varibles_numericas(self):\n",
    "        \"\"\"Devuelve una lista con las variables numericas de un df\"\"\"\n",
    "        return [column_name for column_name, data_type in zip(self.df.columns, self.df.dtypes) if ((data_type != 'category') and  np.issubdtype(data_type, np.number))]\n",
    "    \n",
    "    def detecion_outlier(self,nombre_columna,q=.1):\n",
    "        \"\"\" \n",
    "        Funcion para detectar valores atípicos (utiliers) de una columna especifica usando cuantiles.\n",
    "        Por defecto se usa Deciles / dividiendo la distribucion en 10 partes, pero ajsutando el valor de\n",
    "          q = 0.25 se trabajaria con cuartiles.\n",
    "        La funcion devuelve una \"lista/pandas.core.indexes.numeric.Int64Index\"  con los indices de los \n",
    "        valores atípicos del df\n",
    "        \"\"\"\n",
    "        # try:\n",
    "        #calculo de cuantiles\n",
    "        Q1 = self.df[nombre_columna].quantile(q)\n",
    "        Q3 = self.df[nombre_columna].quantile(1-q)\n",
    "        IQR = Q3-Q1\n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        indice_filas_eliminar = self.df.index[(self.df[nombre_columna] < limite_inferior) | (self.df[nombre_columna] > limite_superior) ]\n",
    "        return indice_filas_eliminar   \n",
    "\n",
    "    def eliminacion_outlier(self,nombre_columna,q=0.1):\n",
    "        \"\"\" \n",
    "        Funcion para eliminar valores atípicos (outliers) de una columna especifica usando cuantiles.\n",
    "        La funcion no devuelve nada porque los cambios se hacen en el df que se pasa por referencia\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if nombre_columna in self.varibles_numericas():\n",
    "                indices = self.detecion_outlier(nombre_columna,q)\n",
    "                self.df = self.df.drop(indices)\n",
    "                self.df.reset_index(inplace=True,drop=True)\n",
    "            else:\n",
    "                print(\"La variable no es numerica\")\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "            \n",
    "    def guardar_transformador(self,nombre_columna,transformador):\n",
    "        \"\"\"Metodo para guardar transformador aplicado, se almacenan en lista, si se\n",
    "        aplican dos o mas se almacenaran en la secuencia aplicada\"\"\"\n",
    "        if nombre_columna in list(self.transformaciones.keys()):\n",
    "            self.transformaciones[nombre_columna] = self.transformaciones[nombre_columna]+[transformador]\n",
    "        else:\n",
    "            self.transformaciones[nombre_columna] = [transformador]\n",
    "            \n",
    "    def Transf_MinMaxScaler(self,nombre_columna):\n",
    "        \"\"\"crea objeto que Transforma los valores de la columna indicada \n",
    "        usando MinMaxScaler de sklear, devuelve el objeto para transformar futuros valores\"\"\"\n",
    "        try:\n",
    "            if nombre_columna in self.varibles_numericas():\n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                escalador = scaler.fit(self.df[nombre_columna].values.reshape(-1, 1))\n",
    "                return escalador\n",
    "            else:\n",
    "                print(\"La variable no es numerica\")\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def Transf_Quantile(self,nombre_columna):\n",
    "        \"\"\"crea objeto para Transformar los valores de la columna indicada  \n",
    "        usando  QuantileTransformer de sklearn\"\"\"\n",
    "        try:\n",
    "            if nombre_columna in self.varibles_numericas():\n",
    "                scaler = preprocessing. QuantileTransformer()\n",
    "                escalador = scaler.fit(self.df[nombre_columna].values.reshape(-1, 1))\n",
    "                return escalador\n",
    "            else:\n",
    "                print(\"La variable no es numerica\")\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)   \n",
    "\n",
    "    def Transf_OneHot_binario(self, nombre_columna):\n",
    "        \"\"\"Crea objeto para transformacion  OneHot cuando la varible es binaria, devuelve\n",
    "        el transformador ya entrenado\"\"\"\n",
    "        try:\n",
    "            value_var = self.df[nombre_columna].astype(\"category\")\n",
    "            codificador_oneHot = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "            codificacion = codificador_oneHot.fit(pd.DataFrame(value_var, columns=[nombre_columna]))\n",
    "            return codificacion\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def Transf_OneHot(self, nombre_columna):\n",
    "        \"\"\"crea objeto para Transformar los valores de la columna indicada  \n",
    "        usando  OneHot encoder de sklearn, devuelve el transformador entrenado \"\"\"\n",
    "        try:\n",
    "            value_var = self.df[nombre_columna].astype(\"category\")\n",
    "            codificador_oneHot = OneHotEncoder(handle_unknown='ignore')\n",
    "            codificacion = codificador_oneHot.fit(pd.DataFrame(value_var, columns=[nombre_columna]))\n",
    "            return codificacion\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def Transf_woe(self,nombre_columna,nombre_target):\n",
    "        \"\"\"crea el objeto para Transformar los valores de la columna indicada  \n",
    "        usando woe de OptimalBinning,\n",
    "        Distinge de variables numericas y categoricas\n",
    "        Devuelve el objeto transoformador\"\"\"\n",
    "        try:\n",
    "            data_type = self.df[nombre_columna].dtypes\n",
    "            target = self.df[nombre_target]\n",
    "            x = self.df.loc[:,nombre_columna]\n",
    "            if (data_type == 'object' or data_type.name == 'category'):  \n",
    "                optb = OptimalBinning(name = nombre_columna,dtype ='categorical',solver='mip')\n",
    "                optb.fit(x,target)\n",
    "            elif np.issubdtype(data_type, np.number):\n",
    "                optb = OptimalBinning(name = nombre_columna,dtype = 'numerical',solver='cp')\n",
    "                optb.fit(x,target)\n",
    "            else:\n",
    "                print(\"La variable se de convertir a tipo numerica o categorica\")\n",
    "                optb = None\n",
    "                \n",
    "            return optb\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)        \n",
    "\n",
    "    def calc_matriz_correlacion(self, columnas=None,filas=None):\n",
    "        \"\"\"metodo para la creacion de la matriz de correlacion, se pude ajustar el numero de filas y las columnas\n",
    "        a calcular para la correlacion\"\"\"\n",
    "        try:\n",
    "            if self.matriz_correlacion is None or self.matriz_correlacion.empty:\n",
    "                if columnas:\n",
    "                    # Se confirma que las columnas existan y sean numericas\n",
    "                    columnas = [ col for col in columnas if col in self.varibles_numericas()]\n",
    "                else:\n",
    "                    columnas = self.varibles_numericas()\n",
    "                if filas:\n",
    "                    data_set = self.df[columnas].sample(filas)\n",
    "                    data_set.reset_index(inplace=True,drop=True)\n",
    "                else:\n",
    "                    data_set = self.df[columnas]\n",
    "                self.matriz_correlacion = data_set.corr(method='pearson', numeric_only=True)\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)    \n",
    "\n",
    "    def clasificacion_correlacion(self, target_name ,nivel_correlacion_target = 0.3, nivel_correlacion_inter_variables = 0.3):\n",
    "        \"\"\"Metodo para clasificar las variables en funcion del nivel de correlacion \n",
    "        1. Entre las variables y el objetivo (target_name), escogiendo las que tengan una \n",
    "        Moderada correlación |corr| > 0.3 pero se puede ajustar si se desea.\n",
    "        2. Entre las mismas variables permitiendo hasta una Moderada correlación |corr| < 0.3  entre ellas\n",
    "        con el objetivo de reducir la multicolinalidad\"\"\"\n",
    "\n",
    "        try:\n",
    "            # Calculo de la correlacion para todas las variables\n",
    "            self.calc_matriz_correlacion()\n",
    "            matriz = self.matriz_correlacion\n",
    "\n",
    "            #Verificacion de la correlacion entre todas las variables y el target, ordenadas de mayor a menor\n",
    "            signals = []\n",
    "            for i in range(len(matriz)):\n",
    "                for j in range(i+1, len(matriz)):\n",
    "                    signal_1 = matriz.columns[i]\n",
    "                    signal_2 = matriz.columns[j]\n",
    "                    correlation = abs(matriz.iloc[i, j])\n",
    "                    signals.append([signal_1, signal_2, correlation])\n",
    "            df_correlacion = pd.DataFrame(signals, columns=['sig_1', 'sig_2', 'nivel_correlacion'])\n",
    "            df_correlacion_mod = df_correlacion[df_correlacion['sig_2'] == target_name].sort_values(by='nivel_correlacion', ascending=False)\n",
    "            variables_x = list(df_correlacion_mod [df_correlacion_mod['nivel_correlacion']>nivel_correlacion_target]['sig_1'])\n",
    "\n",
    "            # Verificacion de la correlacion entre variables \n",
    "            for i, variable1 in enumerate(variables_x):\n",
    "                for variable2 in variables_x[i+1:]:\n",
    "                    mask = (df_correlacion['sig_1'] == variable1) & (df_correlacion['sig_2'] == variable2)\n",
    "                    val_corr = list(df_correlacion[mask]['nivel_correlacion'])\n",
    "                    if not val_corr:\n",
    "                        mask = (df_correlacion['sig_1'] == variable2) & (df_correlacion['sig_2'] == variable1)\n",
    "                        val_corr = list(df_correlacion[mask]['nivel_correlacion'])\n",
    "                    val_corr = val_corr[0] if val_corr else 0\n",
    "                    if val_corr > nivel_correlacion_inter_variables:\n",
    "                        if variable2 in variables_x:\n",
    "                            variables_x.remove(variable2)\n",
    "            return variables_x\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    \n",
    "    def crea_EDAD(self,nombre_columna = 'EDAD'):\n",
    "        \"\"\"Para crear una variable EDAD  se usa como referencia la fecha actual,\n",
    "        independiente del momento en que se corra el programa, se calcula la diferencia entre\n",
    "        la fecha de nacimiento provista y la fecha actual\n",
    "        \"\"\"\n",
    "        try:\n",
    "            fecha_actual = datetime.datetime.now()\n",
    "            self.df[nombre_columna] = (fecha_actual - self.df['FECHANACIMIENTO']).dt.days // 365\n",
    "            self.df.drop(columns=['ANIO', 'MES','FECHANACIMIENTO'], inplace=True)\n",
    "            # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "            \n",
    "    def crea_EDAD_NORM(self,nombre_columna = 'EDAD'):\n",
    "        \"\"\"Para crear una variable EDAD normalizada se usa como referencia la fecha actual,\n",
    "        independiente del momento en que se corra el programa, se calcula la diferencia entre\n",
    "        la fecha de nacimiento provista y la fecha actual, se aplica una eliminacion de outliers\n",
    "        y una transformacion estandar normalizando entre el valor minimo y maximo.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            fecha_actual = datetime.datetime.now()\n",
    "            self.df[nombre_columna] = (fecha_actual - self.df['FECHANACIMIENTO']).dt.days // 365\n",
    "            self.eliminacion_outlier(nombre_columna)\n",
    "            escalador = self.Transf_MinMaxScaler(nombre_columna) \n",
    "            self.df[nombre_columna] = escalador.transform(self.df[nombre_columna].values.reshape(-1, 1)) \n",
    "            self.guardar_transformador(nombre_columna,escalador)\n",
    "            self.df.drop(columns=['ANIO', 'MES','FECHANACIMIENTO'], inplace=True)\n",
    "        \n",
    "            # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def mod_columna_Transf_Quantile(self,nombre_columna):\n",
    "        \"\"\"Modifica la columna indicada utilizando el Transf_Quantile, \n",
    "        alamcena el nombre de la columna modificada y el objeto utilizado para la transformacion\"\"\"\n",
    "        try:\n",
    "            escalador = self.Transf_Quantile(nombre_columna)\n",
    "            self.df[nombre_columna] = escalador.transform(self.df[nombre_columna].values.reshape(-1, 1))\n",
    "            self.guardar_transformador(nombre_columna,escalador)\n",
    "            \n",
    "            # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def mod_columna_OneHot_binario(self,nombre_columna):\n",
    "        \"\"\"Modifica la columna indicada utilizando OneHot_binario, \n",
    "        almacena el nombre de la columna modificada y \n",
    "        el objeto utilizado para la transformacion\"\"\"\n",
    "        try:\n",
    "            escalador = self.Transf_OneHot_binario(nombre_columna)\n",
    "            arreglo = escalador.transform(preproceso.df[[nombre_columna]]).toarray()\n",
    "            self.df[nombre_columna] = arreglo.astype(int)\n",
    "            self.guardar_transformador(nombre_columna,escalador)\n",
    "    \n",
    "             # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "    def mod_columna_OneHot(self,nombre_columna):\n",
    "        try:\n",
    "            escalador = self.Transf_OneHot(nombre_columna)\n",
    "            arreglo = escalador.transform(preproceso.df[[nombre_columna]]).toarray()\n",
    "            columnas_codificadas = escalador.get_feature_names_out([nombre_columna])\n",
    "            df_codificado = pd.DataFrame(arreglo, columns=columnas_codificadas)\n",
    "\n",
    "            #Se introducen en df los valores codificados\n",
    "            pos = self.df.columns.get_loc(nombre_columna)\n",
    "            for col in df_codificado.columns:\n",
    "                self.df.insert(pos, col, df_codificado[col])\n",
    "                pos += 1\n",
    "            self.df.drop(columns=[nombre_columna], inplace=True)\n",
    "            self.guardar_transformador(nombre_columna,escalador)\n",
    "            \n",
    "             # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "        \n",
    "    def mod_woe(self,nombre_columna,nombre_target,metrica = \"woe\"):\n",
    "        \"\"\"Metodo para transformar los elementos de una columna \n",
    "        usando woe de OptimalBinning, se pueden utilizar otras metricas \n",
    "        como: \"event_rate\", \"woe\", \"indices\" and \"bins\" .\"\"\"\n",
    "        try:\n",
    "            escalador = self.Transf_woe(nombre_columna,nombre_target)\n",
    "            x = self.df.loc[:,nombre_columna]\n",
    "            self.df[nombre_columna] = escalador.transform(x, metric=metrica)\n",
    "            self.guardar_transformador(nombre_columna,escalador)\n",
    "\n",
    "             # Se actualiza la instancia de la clase revisor_data_csv\n",
    "            #self.revisor_data.df = self.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)  \n",
    "preproceso = preprocesamiento(revision)\n",
    "def grafica_confusion_matrix(y_test, y_test_predictions):\n",
    "    conf_matrix = confusion_matrix(y_test, y_test_predictions)\n",
    "    fig, ax = plt.subplots(figsize=(8,6), dpi=100)\n",
    "    display = ConfusionMatrixDisplay(conf_matrix)\n",
    "    ax.set(title='Confusion Matrix')\n",
    "    display.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f507365-4b50-4bc3-9c9c-662757cb599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99882"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproceso = preprocesamiento(revision)\n",
    "preproceso.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8d58c-cad3-4a1f-8923-845388bbfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelos:\n",
    "    def __init__(self,revisor_data):\n",
    "        \"\"\"\n",
    "        Constructor de la clase recibe el objeto instanciado de la clase revisor_data_csv.\n",
    "        La clase consta de diferentes modelos cada uno se compone de 3 elementos:\n",
    "            -Transformacion: Proceso de limpieza y normalizacion de la data\n",
    "            -Seleccion: Proceso de seleccion de las caracteristicas mas importantes a utilizar en modelo\n",
    "            -Modelo: Diseño del modelo ML a utilizar\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Se carga el df \n",
    "            self.revisor_data = revisor_data\n",
    "            self.df = self.revisor_data.df\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "\n",
    "    #Modelo lineal 1\n",
    "    def Lin_reg1(self):\n",
    "        \"\"\"\n",
    "        Modelo de regresion logistica con:\n",
    "            1. Transformacion en columnas:  QuantileTransformer para 'INGRESO'\n",
    "                                            MinMaxScaler para 'MORAS'\n",
    "                                            OneHotEncoder para 'SEXO' , 'ESTADO'y 'ESTADOCIVIL'\n",
    "                                            Normalizer para el resto de las variables\n",
    "            2. Seleccion de caracteristicas SelectKBest(f_classif, k=3)\n",
    "            3. Modelo de ML  LinearSVC\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "\n",
    "            \n",
    "    #Este metodo esta repetido en la clase graficos, al final se debe mejorar el codigo ya sea uniendo todas las clases o usando herencias.\n",
    "    def varibles_numericas(self):\n",
    "        \"\"\"Devuelve una lista con las variables numericas de un df\"\"\"\n",
    "        return [column_name for column_name, data_type in zip(self.df.columns, self.df.dtypes) if ((data_type != 'category') and  np.issubdtype(data_type, np.number))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697d677-9895-49b0-bf7d-68e2d14336e8",
   "metadata": {},
   "source": [
    "# Comparando modelo de regresion lineal con diferentes transformaciones a la entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae06923-b720-4592-8a55-77b626e58fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrando el mejor valor de k para el filtro = SelectKBest(chi2, k=??????) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "175d8f15-18a7-421f-9f66-e407c0637405",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio ponderado de 'best_k': 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def modelo_LinearSVC():\n",
    "    ct = ColumnTransformer([('Quantile', QuantileTransformer(n_quantiles=10, random_state=0), ['INGRESO']),\n",
    "                            ('MinMax',MinMaxScaler(), ['MORAS'] ),\n",
    "                            ('Ohe_bi ',OneHotEncoder(handle_unknown='ignore', drop='first'), ['SEXO']),\n",
    "                            ('Ohe',OneHotEncoder(handle_unknown='ignore'), ['ESTADO','ESTADOCIVIL'] ),\n",
    "                            ('Normal',Normalizer(),['MARCACIONES','CONTACTOS','M1','C1','M2','C2','M3','C3'])\n",
    "                            ]\n",
    "                            , remainder='passthrough')#.set_output(transform='pandas')\n",
    "    \n",
    "    filtro = SelectKBest(chi2, k=5) \n",
    "    modelo = LinearSVC(class_weight='balanced',max_iter=10000)\n",
    "    pipe = make_pipeline(ct,filtro, modelo)\n",
    "    \n",
    "    modelo_final = GridSearchCV(estimator = pipe,\n",
    "                                 param_grid = {'selectkbest__k': list(range(2,len(X_train.columns))) },\n",
    "                         scoring = {'f1_score': make_scorer(f1_score)\n",
    "                                   },\n",
    "                         refit = 'f1_score',\n",
    "                         #verbose=4,\n",
    "                         return_train_score = True,\n",
    "                        cv = 5)\n",
    "    return modelo_final\n",
    "\n",
    "df_param_selectkbest__k = pd.DataFrame()\n",
    "df_reporte = pd.DataFrame([],columns = ['precision_class_0','precision_class_1', \n",
    "                                        'recall_class_0','recall_class_1',\n",
    "                                        'f1-score_class_0','f1-score_class_1','accuracy','best_k'])\n",
    "repeticiones = 20\n",
    "for n in range(1,repeticiones):\n",
    "    preproceso = preprocesamiento(revision)\n",
    "    preproceso.df = preproceso.df.sample(10000)\n",
    "    preproceso.crea_EDAD_NORM('EDAD')\n",
    "\n",
    "    X = preproceso.df.drop(columns=['TARGET'])\n",
    "    y = preproceso.df['TARGET'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=69)\n",
    "    \n",
    "    modelo_final =  modelo_LinearSVC()\n",
    "    modelo_final.fit(X_train, y_train)\n",
    "    \n",
    "    resultado = pd.DataFrame(modelo_final.cv_results_)\n",
    "    reporte = classification_report(y_test, modelo_final.predict(X_test),output_dict=True,target_names=['class 0', 'class 1'])\n",
    "    \n",
    "    df_param_selectkbest__k[n] = list(resultado['rank_test_f1_score'])\n",
    "    df_reporte_row = [reporte['class 0']['precision'],reporte['class 1']['precision'],\n",
    "                      reporte['class 0']['recall'],reporte['class 1']['recall'],\n",
    "                      reporte['class 0']['f1-score'],reporte['class 1']['f1-score'],reporte['accuracy'],modelo_final.best_params_['selectkbest__k']]\n",
    "    df_reporte = pd.concat([df_reporte, pd.DataFrame([df_reporte_row], columns=df_reporte.columns)], ignore_index=True)\n",
    "\n",
    "accuracy_values = df_reporte['accuracy'].to_numpy()\n",
    "best_k_values = df_reporte['best_k'].to_numpy()\n",
    "\n",
    "# Calcular el promedio ponderado\n",
    "weighted_average = int(np.average(best_k_values, weights=accuracy_values))\n",
    "\n",
    "print(f\"Promedio ponderado de 'best_k': {weighted_average}\")\n",
    "\n",
    "# # #anova_svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1133230d-c437-4fb9-ae49-e096ae0de999",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_class_0</th>\n",
       "      <th>precision_class_1</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>f1-score_class_0</th>\n",
       "      <th>f1-score_class_1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>best_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875948</td>\n",
       "      <td>0.720685</td>\n",
       "      <td>0.902529</td>\n",
       "      <td>0.663030</td>\n",
       "      <td>0.889040</td>\n",
       "      <td>0.690657</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.894619</td>\n",
       "      <td>0.705195</td>\n",
       "      <td>0.897840</td>\n",
       "      <td>0.697943</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.701550</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.895787</td>\n",
       "      <td>0.681879</td>\n",
       "      <td>0.894993</td>\n",
       "      <td>0.683715</td>\n",
       "      <td>0.895390</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889520</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.918809</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.903927</td>\n",
       "      <td>0.709980</td>\n",
       "      <td>0.855667</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.709720</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.899152</td>\n",
       "      <td>0.702240</td>\n",
       "      <td>0.849333</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.894573</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.903009</td>\n",
       "      <td>0.693402</td>\n",
       "      <td>0.898771</td>\n",
       "      <td>0.702951</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.886424</td>\n",
       "      <td>0.702413</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.671795</td>\n",
       "      <td>0.893160</td>\n",
       "      <td>0.686763</td>\n",
       "      <td>0.840667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.888343</td>\n",
       "      <td>0.706965</td>\n",
       "      <td>0.899186</td>\n",
       "      <td>0.682741</td>\n",
       "      <td>0.893732</td>\n",
       "      <td>0.694642</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.898098</td>\n",
       "      <td>0.720960</td>\n",
       "      <td>0.899728</td>\n",
       "      <td>0.717337</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.719144</td>\n",
       "      <td>0.851333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.894856</td>\n",
       "      <td>0.702806</td>\n",
       "      <td>0.894856</td>\n",
       "      <td>0.702806</td>\n",
       "      <td>0.894856</td>\n",
       "      <td>0.702806</td>\n",
       "      <td>0.844667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.901683</td>\n",
       "      <td>0.702156</td>\n",
       "      <td>0.902082</td>\n",
       "      <td>0.701211</td>\n",
       "      <td>0.901883</td>\n",
       "      <td>0.701684</td>\n",
       "      <td>0.852333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.889823</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.898169</td>\n",
       "      <td>0.672799</td>\n",
       "      <td>0.893976</td>\n",
       "      <td>0.682212</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.902012</td>\n",
       "      <td>0.693277</td>\n",
       "      <td>0.903989</td>\n",
       "      <td>0.688456</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.690858</td>\n",
       "      <td>0.852333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.904594</td>\n",
       "      <td>0.741848</td>\n",
       "      <td>0.915103</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.909818</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.889183</td>\n",
       "      <td>0.729252</td>\n",
       "      <td>0.910077</td>\n",
       "      <td>0.681067</td>\n",
       "      <td>0.899509</td>\n",
       "      <td>0.704336</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.899066</td>\n",
       "      <td>0.705726</td>\n",
       "      <td>0.901471</td>\n",
       "      <td>0.700132</td>\n",
       "      <td>0.900267</td>\n",
       "      <td>0.702918</td>\n",
       "      <td>0.850667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.895706</td>\n",
       "      <td>0.736769</td>\n",
       "      <td>0.915361</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.712458</td>\n",
       "      <td>0.857667</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.889037</td>\n",
       "      <td>0.700134</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.676585</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.688158</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.891372</td>\n",
       "      <td>0.698558</td>\n",
       "      <td>0.896583</td>\n",
       "      <td>0.686856</td>\n",
       "      <td>0.893970</td>\n",
       "      <td>0.692658</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precision_class_0  precision_class_1  recall_class_0  recall_class_1  \\\n",
       "0            0.875948           0.720685        0.902529        0.663030   \n",
       "1            0.894619           0.705195        0.897840        0.697943   \n",
       "2            0.895787           0.681879        0.894993        0.683715   \n",
       "3            0.889520           0.746479        0.918809        0.676884   \n",
       "4            0.895954           0.709720        0.902373        0.694915   \n",
       "5            0.894573           0.712766        0.903009        0.693402   \n",
       "6            0.886424           0.702413        0.900000        0.671795   \n",
       "7            0.888343           0.706965        0.899186        0.682741   \n",
       "8            0.898098           0.720960        0.899728        0.717337   \n",
       "9            0.894856           0.702806        0.894856        0.702806   \n",
       "10           0.901683           0.702156        0.902082        0.701211   \n",
       "11           0.889823           0.691892        0.898169        0.672799   \n",
       "12           0.902012           0.693277        0.903989        0.688456   \n",
       "13           0.904594           0.741848        0.915103        0.716535   \n",
       "14           0.889183           0.729252        0.910077        0.681067   \n",
       "15           0.899066           0.705726        0.901471        0.700132   \n",
       "16           0.895706           0.736769        0.915361        0.689700   \n",
       "17           0.889037           0.700134        0.899416        0.676585   \n",
       "18           0.891372           0.698558        0.896583        0.686856   \n",
       "\n",
       "    f1-score_class_0  f1-score_class_1  accuracy best_k  \n",
       "0           0.889040          0.690657  0.836667      3  \n",
       "1           0.896226          0.701550  0.846000     14  \n",
       "2           0.895390          0.682796  0.842667      9  \n",
       "3           0.903927          0.709980  0.855667      8  \n",
       "4           0.899152          0.702240  0.849333     10  \n",
       "5           0.898771          0.702951  0.849000     12  \n",
       "6           0.893160          0.686763  0.840667      4  \n",
       "7           0.893732          0.694642  0.842333     13  \n",
       "8           0.898912          0.719144  0.851333     14  \n",
       "9           0.894856          0.702806  0.844667     14  \n",
       "10          0.901883          0.701684  0.852333      6  \n",
       "11          0.893976          0.682212  0.841000      5  \n",
       "12          0.903000          0.690858  0.852333     14  \n",
       "13          0.909818          0.728972  0.864667     14  \n",
       "14          0.899509          0.704336  0.850000     14  \n",
       "15          0.900267          0.702918  0.850667      5  \n",
       "16          0.905426          0.712458  0.857667     13  \n",
       "17          0.894196          0.688158  0.842000     14  \n",
       "18          0.893970          0.692658  0.842333     10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reporte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb5cd7-d00c-4e57-be7a-45058caeae8d",
   "metadata": {},
   "source": [
    "## Implementado el modelo SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba608b-9f0c-40da-8f0d-9c7be0c06354",
   "metadata": {},
   "source": [
    "`SGDClassifier` es una implementación del algoritmo de descenso de gradiente estocástico (SGD) para problemas de clasificación en scikit-learn. Es un clasificador lineal que utiliza el enfoque de optimización iterativa basado en el gradiente para ajustar los parámetros del modelo.\n",
    "\n",
    "El funcionamiento básico de `SGDClassifier` se puede resumir en los siguientes pasos:\n",
    "\n",
    "1. Preparación de los datos: Antes de entrenar el modelo, los datos de entrenamiento deben estar en un formato adecuado. Esto generalmente implica realizar la codificación de variables categóricas, escalar las características numéricas y dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "2. Inicialización de parámetros: Se inicializan los pesos y sesgos del modelo. Estos parámetros se actualizan durante el proceso de entrenamiento para minimizar la función de pérdida.\n",
    "\n",
    "3. Selección de la función de pérdida: Se elige una función de pérdida apropiada para el problema de clasificación. Algunas opciones comunes incluyen la regresión logística (`log`), la pérdida de entropía cruzada (`log` con el parámetro `loss='log'`), la pérdida de bisagra (`hinge`) para máquinas de vectores de soporte lineales, entre otras.\n",
    "\n",
    "4. Ciclo de entrenamiento: El modelo itera sobre los datos de entrenamiento en mini lotes (muestras seleccionadas aleatoriamente) y actualiza los parámetros en función del gradiente de la función de pérdida. Esta es la característica principal del SGD, ya que realiza actualizaciones de parámetros más frecuentes en lugar de utilizar todo el conjunto de datos en cada iteración.\n",
    "\n",
    "5. Actualización de parámetros: Durante cada iteración, se calcula el gradiente de la función de pérdida con respecto a los parámetros del modelo y se actualizan los pesos y sesgos utilizando un tamaño de paso (también llamado tasa de aprendizaje). Esto se repite hasta que se alcanza un criterio de convergencia predefinido, como el número máximo de iteraciones o una mejora mínima en la función de pérdida.\n",
    "\n",
    "6. Predicción: Una vez entrenado el modelo, se pueden realizar predicciones en nuevos datos utilizando la función `predict`. El clasificador asigna una etiqueta a cada muestra en función de la función de decisión o probabilidad.\n",
    "\n",
    "Es importante destacar que `SGDClassifier` es eficiente y escalable, ya que se puede utilizar en conjuntos de datos grandes debido a su enfoque de optimización estocástica y su capacidad para procesar datos en mini lotes. Además, permite el ajuste de hiperparámetros como la tasa de aprendizaje, la regularización L1 o L2 y la penalización elástica, lo que brinda flexibilidad en la configuración del modelo.\n",
    "\n",
    "En resumen, `SGDClassifier` es un clasificador lineal eficiente y escalable que utiliza el algoritmo de descenso de gradiente estocástico para ajustar los parámetros del modelo. Es adecuado para problemas de clasificación binaria y multiclase y ofrece opciones de regularización y diferentes funciones de pérdida para adaptarse a diferentes escenarios de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8223c1-a235-452e-9893-f2acf5ae0be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeticion: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list.append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m best_params \u001b[38;5;241m=\u001b[39m modelo_final\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     74\u001b[0m best_model \u001b[38;5;241m=\u001b[39m modelo_final\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m---> 75\u001b[0m \u001b[43mresultado\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m modelo_final\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Calcular métricas de evaluación del modelo\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: list.append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# preproceso = preprocesamiento(revision)\n",
    "# preproceso.df = preproceso.df.sample(10000)\n",
    "# preproceso.crea_EDAD_NORM('EDAD')\n",
    "\n",
    "# # Dividir datos en conjunto de entrenamiento y prueba\n",
    "# X = preproceso.df.drop(columns=['TARGET'])\n",
    "# y = preproceso.df['TARGET'].to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "def modelo_SGDClassifier():\n",
    "    pipes_bining = []\n",
    "    for columna in X_train.columns:\n",
    "        pipes_bining.append((columna + '_Tr', Pipeline([('columna', BinningProcess(variable_names=[columna]))]), [columna]))\n",
    "    ct_woe = ColumnTransformer(pipes_bining)\n",
    "    \n",
    "    \n",
    "    filtro = SelectKBest(chi2, k=5) \n",
    "    \n",
    "    # implementacion del modelo completo\n",
    "    pipeline = Pipeline([\n",
    "        ('Transformacion_woe', ct_woe),\n",
    "        ('Transformacion_0_1',MinMaxScaler()),\n",
    "        ('Reduccion_var', filtro),\n",
    "        ('classifier', SGDClassifier())\n",
    "    ])\n",
    "\n",
    "    # Definir los posibles valores de hiperparámetros para GridSearchCV\n",
    "    param_grid = {\n",
    "        'classifier__loss': ['hinge', 'log_loss'],  # Función de pérdida: logística o bisagra\n",
    "        'classifier__alpha': [0.0001, 0.001, 0.01],  # Tasa de regularización\n",
    "        'classifier__class_weight': ['balanced', {0: 0.2, 1: 0.8}]  # Ponderación de clases desbalanceadas\n",
    "    }\n",
    "    \n",
    "    # Crear GridSearchCV para ajustar los hiperparámetros\n",
    "    grid_search = GridSearchCV(pipeline, \n",
    "                               param_grid, \n",
    "                               cv=5,   \n",
    "                               #verbose =2,\n",
    "                               scoring='f1')\n",
    "    return grid_search\n",
    "\n",
    "df_reporte = pd.DataFrame([],columns = ['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "\n",
    "resultado = []\n",
    "repeticiones = 5   # cambiar 5\n",
    "for _ in range(repeticiones):\n",
    "    print('repeticion:',_)\n",
    "    preproceso = preprocesamiento(revision)\n",
    "    preproceso.df = preproceso.df.sample(1000)\n",
    "    preproceso.crea_EDAD()\n",
    "\n",
    "    X = preproceso.df.drop(columns=['TARGET'])\n",
    "    y = preproceso.df['TARGET'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=69)\n",
    "    \n",
    "    modelo_final = modelo_SGDClassifier()\n",
    "    modelo_final.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Obtener los mejores hiperparámetros y el mejor modelo\n",
    "    best_params = modelo_final.best_params_\n",
    "    best_model = modelo_final.best_estimator_\n",
    "    resultado.append((best_params,best_model))\n",
    "    \n",
    "    y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de evaluación del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    df_reporte_row = [accuracy,precision,recall,f1 ]\n",
    "    df_reporte = pd.concat([df_reporte, pd.DataFrame([df_reporte_row], columns=df_reporte.columns)], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48eaa346-8ccc-48ba-b639-c60b46162a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_class_0</th>\n",
       "      <th>precision_class_1</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>f1-score_class_0</th>\n",
       "      <th>f1-score_class_1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.696629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.902222</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.898230</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.900222</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.697987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.891041</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.734463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_class_0  precision_class_1  recall_class_0  recall_class_1  \\\n",
       "0           0.929293           0.607843        0.821429        0.815789   \n",
       "1           0.902222           0.693333        0.898230        0.702703   \n",
       "2           0.943590           0.676190        0.844037        0.865854   \n",
       "3           0.940000           0.650000        0.843049        0.844156   \n",
       "4           0.866667           0.653333        0.882353        0.620253   \n",
       "\n",
       "   f1-score_class_0  f1-score_class_1  accuracy  accuracy_score  \\\n",
       "0          0.872038          0.696629  0.820000        0.820000   \n",
       "1          0.900222          0.697987  0.850000        0.850000   \n",
       "2          0.891041          0.759358  0.850000        0.850000   \n",
       "3          0.888889          0.734463  0.843333        0.843333   \n",
       "4          0.874439          0.636364  0.813333        0.813333   \n",
       "\n",
       "   precision_score  recall_score  f1_score  \n",
       "0         0.607843      0.815789  0.696629  \n",
       "1         0.693333      0.702703  0.697987  \n",
       "2         0.676190      0.865854  0.759358  \n",
       "3         0.650000      0.844156  0.734463  \n",
       "4         0.653333      0.620253  0.636364  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60f2c16-e31f-4c0d-bfd7-2eaf9553aabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__alpha</th>\n",
       "      <th>param_classifier__class_weight</th>\n",
       "      <th>param_classifier__loss</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.192196</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__cla...</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.713356</td>\n",
       "      <td>0.044859</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.181035</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__cla...</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.692418</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.296739</td>\n",
       "      <td>0.115129</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__cla...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.047162</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.229665</td>\n",
       "      <td>0.106829</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.0001, 'classifier__cla...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708140</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.272672</td>\n",
       "      <td>0.154092</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.001, 'classifier__clas...</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.753175</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.234657</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.001, 'classifier__clas...</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.736597</td>\n",
       "      <td>0.055962</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.201042</td>\n",
       "      <td>0.110415</td>\n",
       "      <td>0.026617</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.001, 'classifier__clas...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.752442</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.321947</td>\n",
       "      <td>0.209321</td>\n",
       "      <td>0.041628</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.001, 'classifier__clas...</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741364</td>\n",
       "      <td>0.039288</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.198027</td>\n",
       "      <td>0.095893</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__class...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.744426</td>\n",
       "      <td>0.050066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.209866</td>\n",
       "      <td>0.113173</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__class...</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.743382</td>\n",
       "      <td>0.040327</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.181033</td>\n",
       "      <td>0.100573</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__class...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.733903</td>\n",
       "      <td>0.039521</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.242266</td>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: 0.2, 1: 0.8}</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'classifier__alpha': 0.01, 'classifier__class...</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.709007</td>\n",
       "      <td>0.047186</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.192196      0.112547         0.026223        0.000747   \n",
       "1        1.181035      0.101328         0.027419        0.001200   \n",
       "2        1.296739      0.115129         0.030821        0.008619   \n",
       "3        1.229665      0.106829         0.030019        0.005554   \n",
       "4        1.272672      0.154092         0.026618        0.001499   \n",
       "5        1.234657      0.061797         0.026217        0.000749   \n",
       "6        1.201042      0.110415         0.026617        0.001020   \n",
       "7        1.321947      0.209321         0.041628        0.012887   \n",
       "8        1.198027      0.095893         0.026417        0.001498   \n",
       "9        1.209866      0.113173         0.026217        0.000749   \n",
       "10       1.181033      0.100573         0.027218        0.000980   \n",
       "11       1.242266      0.180746         0.026217        0.000981   \n",
       "\n",
       "   param_classifier__alpha param_classifier__class_weight  \\\n",
       "0                   0.0001                       balanced   \n",
       "1                   0.0001                       balanced   \n",
       "2                   0.0001               {0: 0.2, 1: 0.8}   \n",
       "3                   0.0001               {0: 0.2, 1: 0.8}   \n",
       "4                    0.001                       balanced   \n",
       "5                    0.001                       balanced   \n",
       "6                    0.001               {0: 0.2, 1: 0.8}   \n",
       "7                    0.001               {0: 0.2, 1: 0.8}   \n",
       "8                     0.01                       balanced   \n",
       "9                     0.01                       balanced   \n",
       "10                    0.01               {0: 0.2, 1: 0.8}   \n",
       "11                    0.01               {0: 0.2, 1: 0.8}   \n",
       "\n",
       "   param_classifier__loss                                             params  \\\n",
       "0                   hinge  {'classifier__alpha': 0.0001, 'classifier__cla...   \n",
       "1                log_loss  {'classifier__alpha': 0.0001, 'classifier__cla...   \n",
       "2                   hinge  {'classifier__alpha': 0.0001, 'classifier__cla...   \n",
       "3                log_loss  {'classifier__alpha': 0.0001, 'classifier__cla...   \n",
       "4                   hinge  {'classifier__alpha': 0.001, 'classifier__clas...   \n",
       "5                log_loss  {'classifier__alpha': 0.001, 'classifier__clas...   \n",
       "6                   hinge  {'classifier__alpha': 0.001, 'classifier__clas...   \n",
       "7                log_loss  {'classifier__alpha': 0.001, 'classifier__clas...   \n",
       "8                   hinge  {'classifier__alpha': 0.01, 'classifier__class...   \n",
       "9                log_loss  {'classifier__alpha': 0.01, 'classifier__class...   \n",
       "10                  hinge  {'classifier__alpha': 0.01, 'classifier__class...   \n",
       "11               log_loss  {'classifier__alpha': 0.01, 'classifier__class...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.659574           0.773333           0.701299   \n",
       "1            0.607843           0.760563           0.626866   \n",
       "2            0.769231           0.789474           0.701299   \n",
       "3            0.689655           0.773333           0.647887   \n",
       "4            0.789474           0.789474           0.708861   \n",
       "5            0.789474           0.773333           0.692308   \n",
       "6            0.769231           0.789474           0.740741   \n",
       "7            0.759494           0.773333           0.738095   \n",
       "8            0.769231           0.773333           0.740741   \n",
       "9            0.763158           0.767123           0.740741   \n",
       "10           0.769231           0.756757           0.735632   \n",
       "11           0.740741           0.759494           0.645833   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.757576           0.675000         0.713356        0.044859   \n",
       "1            0.782609           0.684211         0.692418        0.069707   \n",
       "2            0.800000           0.684211         0.748843        0.047162   \n",
       "3            0.763158           0.666667         0.708140        0.050930   \n",
       "4            0.794521           0.683544         0.753175        0.047237   \n",
       "5            0.779221           0.648649         0.736597        0.055962   \n",
       "6            0.779221           0.683544         0.752442        0.038090   \n",
       "7            0.769231           0.666667         0.741364        0.039288   \n",
       "8            0.789474           0.649351         0.744426        0.050066   \n",
       "9            0.779221           0.666667         0.743382        0.040327   \n",
       "10           0.750000           0.657895         0.733903        0.039521   \n",
       "11           0.740741           0.658228         0.709007        0.047186   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 9  \n",
       "1                12  \n",
       "2                 3  \n",
       "3                11  \n",
       "4                 1  \n",
       "5                 7  \n",
       "6                 2  \n",
       "7                 6  \n",
       "8                 4  \n",
       "9                 5  \n",
       "10                8  \n",
       "11               10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44d3af-806d-4a86-8f70-4f6a3c8602b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3d6945-94b5-4fa2-929f-6fba1964de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__alpha': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'hinge'}\n",
      "Accuracy: 0.8133333333333334\n",
      "Precision: 0.6533333333333333\n",
      "Recall: 0.620253164556962\n",
      "F1 Score: 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "# Obtener los mejores hiperparámetros y el mejor modelo\n",
    "best_params = modelo_final.best_params_\n",
    "best_model = modelo_final.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ecdff-b428-4571-9077-ea0012891de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d68a5a3-94d9-468a-b895-3af2795651ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       219\n",
      "           1       0.60      0.75      0.67        81\n",
      "\n",
      "    accuracy                           0.80       300\n",
      "   macro avg       0.75      0.79      0.76       300\n",
      "weighted avg       0.82      0.80      0.81       300\n",
      "\n",
      "AUC-ROC Score: 0.8414510400811771\n",
      "Matriz de confusion:\n",
      " [[179  40]\n",
      " [ 20  61]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preproceso = preprocesamiento(revision)\n",
    "preproceso.df = preproceso.df.sample(1000)\n",
    "preproceso.crea_EDAD_NORM('EDAD')\n",
    "\n",
    "X = preproceso.df.drop(columns=['TARGET'])\n",
    "y = preproceso.df['TARGET'].to_numpy()\n",
    "\n",
    "#Una práctica común es utilizar la división estándar, 70% para entrenamiento y el 30% para validación.\n",
    "# MAs adelante se pueden utilizar Validación cruzada, Validación estratificada o Muestreo balanceado.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def mod_lineal1():\n",
    "    \n",
    "ct = ColumnTransformer([('Quantile', QuantileTransformer(n_quantiles=10, random_state=0), ['INGRESO']),\n",
    "                        ('MinMax',MinMaxScaler(), ['MORAS'] ),\n",
    "                        ('Ohe_bi ',OneHotEncoder(handle_unknown='ignore', drop='first'), ['SEXO']),\n",
    "                        ('Ohe',OneHotEncoder(handle_unknown='ignore'), ['ESTADO','ESTADOCIVIL'] ),\n",
    "                        ('Normal',Normalizer(),['MARCACIONES','CONTACTOS','M1','C1','M2','C2','M3','C3'])\n",
    "                        ]\n",
    "                        , remainder='passthrough')#.set_output(transform='pandas')\n",
    "\n",
    "# Modelo de clasificación de Support Vector Machine (SVM)\n",
    "n = 5\n",
    "\n",
    "#RFE (Recursive Feature Elimination) requiere evaluar todas las combinaciones posibles de características en cada paso del proceso de selección.\n",
    "#estimator = SVC(kernel='linear', coef0=1, probability=True) \n",
    "#selector1 = RFE(estimator, n_features_to_select=n)\n",
    "\n",
    "# SequentialFeatureSelector se basa en un enfoque secuencial, donde se van seleccionando características de manera progresiva en función de algún criterio de evaluación\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "selector2 = SequentialFeatureSelector(knn, n_features_to_select=n)\n",
    "\n",
    "\n",
    "#selector_SVC.fit(X_train_trans, y_train)\n",
    "#X_train_trans_red = selector_SVC.transform(X_train_trans)\n",
    "\n",
    " # Modelo de clasificación Regresion logistica con ajuste de desbalance\n",
    "def ajuste_desbalance_LogReg(target):\n",
    "    # Implementación de ajuste en caso de desbalanceo de clases para la implementación en LogisticRegression\n",
    "    unique, counts = np.unique(target, return_counts=True)\n",
    "    numero_clases = len(unique)\n",
    "    val_TARGET_0 = unique[0]\n",
    "    val_TARGET_1 = unique[1]\n",
    "    cant_TARGET_0 = counts[0]\n",
    "    cant_TARGET_1 = counts[1]\n",
    "    total = cant_TARGET_0 + cant_TARGET_1\n",
    "    peso_TARGET_0 = total / (numero_clases * cant_TARGET_0)\n",
    "    peso_TARGET_1 = total / (numero_clases * cant_TARGET_1)\n",
    "    return {val_TARGET_0: round(10*peso_TARGET_0,0), val_TARGET_1: 2*round(10*peso_TARGET_1,0)}\n",
    "LR_balance = LogisticRegression(class_weight = ajuste_desbalance_LogReg(y_train))  #.fit(X_train_trans_red, y_train)\n",
    "\n",
    "# implementacion del modelo completo\n",
    "pipeline = Pipeline([\n",
    "    ('Transformacion_var', ct),\n",
    "    ('Reduccion_var', selector),\n",
    "    ('clasificacion', LR_balance)\n",
    "])\n",
    "pipe = pipeline.fit(X_train, y_train)\n",
    "\n",
    "prediccion = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "# Obtener las métricas de precisión, recall y F1-score\n",
    "report = classification_report(y_test, prediccion)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "# Calcular el valor AUC-ROC\n",
    "y_pred_prob = pipe.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC-ROC Score:\", auc_roc)\n",
    "\n",
    "print(\"Matriz de confusion:\\n\",confusion_matrix(y_test, pipe.predict(X_test)))\n",
    "\n",
    "grafica_confusion_matrix(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc88bb9a-bbca-42ca-b9dd-e2cebc0d77bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.66, 0.93), (0.84, 0.83))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JHO_precision = round(201/(201+105 ),2), round(553/(553+41 ),2)\n",
    "JHO_recall = round(553/(105+553 ),2) , round(201/(201+41),2)\n",
    "JHO_precision, JHO_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175b1f70-a0db-4c7e-b961-bd50e2ea19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.linear_model import SGDClassifier\n",
    " from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c19011cd-5839-4f38-a702-6d2195fc5450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      2224\n",
      "           1       0.65      0.83      0.73       776\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.79      0.84      0.81      3000\n",
      "weighted avg       0.86      0.84      0.85      3000\n",
      "\n",
      "AUC-ROC Score: 0.9006176180189869\n",
      "atris de confusion:\n",
      " [[1880  344]\n",
      " [ 134  642]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preproceso = preprocesamiento(revision)\n",
    "preproceso.df = preproceso.df.sample(10000)\n",
    "preproceso.crea_EDAD_NORM('EDAD')\n",
    "\n",
    "X = preproceso.df.drop(columns=['TARGET'])\n",
    "y = preproceso.df['TARGET'].to_numpy()\n",
    "\n",
    "#Una práctica común es utilizar la división estándar, 70% para entrenamiento y el 30% para validación.\n",
    "# MAs adelante se pueden utilizar Validación cruzada, Validación estratificada o Muestreo balanceado.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=69)\n",
    "\n",
    "\n",
    "#Se utiliza ColumnTransformer para ejustar el modelo incluyendo las transformaciones\n",
    "pipes_bining = []\n",
    "for columna in X_train.columns:\n",
    "    pipes_bining.append((columna + '_Tr', Pipeline([('columna', BinningProcess(variable_names=[columna]))]), [columna]))\n",
    "ct2 = ColumnTransformer(pipes_bining)\n",
    "\n",
    "\n",
    " # Seleccionadores de caracteristicas/ columnas\n",
    "  #  https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\n",
    "n = 5\n",
    "# stimador implementa modelos lineales regularizados con descenso de gradiente estocástico (SGD)\n",
    "estimator = SGDClassifier(max_iter=1000, tol=1e-3,class_weight= 'balanced')\n",
    "\n",
    "# Meta-transformador para seleccionar características basadas en  importance weights.\n",
    "selector = SelectFromModel(estimator,max_features=n)\n",
    "\n",
    "\n",
    "\n",
    " # Modelo de clasificación Regresion logistica con ajuste de desbalance\n",
    "def ajuste_desbalance_LogReg(target):\n",
    "    # Implementación de ajuste en caso de desbalanceo de clases para la implementación en LogisticRegression\n",
    "    unique, counts = np.unique(target, return_counts=True)\n",
    "    numero_clases = len(unique)\n",
    "    val_TARGET_0 = unique[0]\n",
    "    val_TARGET_1 = unique[1]\n",
    "    cant_TARGET_0 = counts[0]\n",
    "    cant_TARGET_1 = counts[1]\n",
    "    total = cant_TARGET_0 + cant_TARGET_1\n",
    "    peso_TARGET_0 = total / (numero_clases * cant_TARGET_0)\n",
    "    peso_TARGET_1 = total / (numero_clases * cant_TARGET_1)\n",
    "    return {val_TARGET_0: round(10*peso_TARGET_0,0), val_TARGET_1: round(10*peso_TARGET_1,0)}\n",
    "LR_balance = LogisticRegression(class_weight = ajuste_desbalance_LogReg(y_train))\n",
    "\n",
    "# implementacion del modelo completo\n",
    "pipeline2 = Pipeline([\n",
    "    ('Transformacion_var', ct2),\n",
    "    ('Reduccion_var', selector ),\n",
    "    ('clasificacion', LR_balance)\n",
    "])\n",
    "\n",
    "pipe2 = pipeline2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "prediccion2 = pipe2.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Obtener las métricas de precisión, recall y F1-score\n",
    "report = classification_report(y_test, prediccion2)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "# Calcular el valor AUC-ROC\n",
    "y_pred_prob = pipe2.predict_proba(X_test)[:, 1]  # Probabilidad de clase positiva\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC-ROC Score:\", auc_roc)\n",
    "\n",
    "print(\"atris de confusion:\\n\",confusion_matrix(y_test, pipe2.predict(X_test)))\n",
    "\n",
    "grafica_confusion_matrix(y_test, prediccion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb3077-20d5-4b2a-94d6-58bb25e889ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bd7b0-8679-4eda-a736-9084e96ee27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b9778-7998-43c0-b0bc-85a2220639c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce2eb0-39a1-4539-a355-54858e8df037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2280f7f-ab6c-4960-b77a-6486d52dc7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d8507-5549-40e0-a80d-85a409c7fa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3330bd4-3dd5-452f-8451-e24838857caa",
   "metadata": {},
   "source": [
    "los 3 modelos que mejor se ajustan a datos no linealmente separables son:\n",
    "\n",
    "Support Vector Machines (SVM): SVM es especialmente efectivo en la clasificación de datos no linealmente separables. Utiliza una función de kernel para mapear los datos a un espacio de mayor dimensión donde los datos pueden ser linealmente separables. Esto permite capturar relaciones no lineales entre las características y mejorar el rendimiento de la clasificación.\r\n",
    "\r\n",
    "Gaussian Processes: Los procesos gaussianos son útiles cuando los datos no se pueden modelar de manera lineal. Estos modelos no paramétricos son capaces de capturar relaciones no lineales y se basan en la estimación de la distribución de probabilidad conjunta de las variables. Pueden adaptarse a patrones complejos y proporcionar incertidumbre en las predicciones.\r\n",
    "\r\n",
    "Decision Trees: Los árboles de decisión son capaces de modelar relaciones no lineales entre las características y la variable objetivo. Estos modelos dividen recursivamente el espacio de características en regiones más pequeñas y realizan decisiones en función de reglas de partición. Pueden capturar patrones no lineales de manera efectiva y son especialmente útiles cuando las relaciones entre las características no son lineales.\r\n",
    "\r\n",
    "En resumen, SVM, Gaussian Processes y Decision Trees son modelos que se destac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034210b-7fe1-4ade-bab8-bf9fcaa4274c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
