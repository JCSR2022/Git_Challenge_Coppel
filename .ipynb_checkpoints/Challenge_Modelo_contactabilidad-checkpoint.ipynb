{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cd4583-45f1-446a-989f-c63856f2de3f",
   "metadata": {},
   "source": [
    "# Challenge Analítica Avanzada e Inteligencia Artificial\n",
    "## Centro de Investigación Coppel\n",
    "\n",
    "### Elaborado por: Jhonathan Santacana\n",
    "\n",
    "### Problema UNO\n",
    "\n",
    "El objetivo de este problema es desarrollar un modelo de contactabilidad que asocie una probabilidad de contacto a cada cliente en función de ciertos segmentos horarios. Para resolver este problema, se utilizará el archivo 20210513_Challenge_AA.csv, que contiene información sociodemográfica y transaccional de los clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736e789-57be-453d-98cf-214b530f9646",
   "metadata": {},
   "source": [
    "## Análisis preliminar y proceso ETL:\n",
    "\n",
    "0. **Revisar Metadata**: Revisa las características del archivo, como el formato, el tipo de datos, los tamaños y las columnas.\n",
    "\n",
    "1. **Cargar los datos del archivo .csv**: Realiza la carga de los datos del archivo .csv en el entorno de trabajo.\n",
    "\n",
    "2. **Seleccionar horario, aplicar filtro y trabajar con un dataframe más pequeño**: Selecciona un horario específico, aplica el filtro correspondiente y trabaja con un dataframe más reducido.\n",
    "\n",
    "3. **Indicar las dimensiones del nuevo archivo**: Indica el número de filas y columnas en el nuevo archivo, así como los nombres de las variables y una descripción general de los datos.\n",
    "\n",
    "4. **Obtener el número de observaciones y valores perdidos**: Calcula el número de observaciones y valores faltantes (NA) en los datos.\n",
    "\n",
    "5. **Calcular medidas estadísticas básicas**: Calcula medidas estadísticas básicas como el promedio, los percentiles, las desviaciones estándar, los valores mínimos y máximos, y la mediana.\n",
    "\n",
    "6. **Elaborar un programa para crear un gráfico que proporcione una visión general de los datos**.\n",
    "\n",
    "7. **Elaborar un programa para crear un gráfico de barras**: Crea un gráfico de barras que muestre la frecuencia de las categorías (discretas) y otro gráfico de barras que muestre la frecuencia de las variables continuas.\n",
    "\n",
    "8. **Analizar las correlaciones entre las variables**: Identifica las correlaciones entre las variables para identificar aquellas que sean linealmente dependientes.\n",
    "\n",
    "9. **Establecer un criterio para determinar los factores influyentes con respecto al objetivo**: Utiliza criterios como el valor de Información Value o el peso de la evidencia (Weight of Evidence) para determinar los factores influyentes en relación con la variable objetivo. Enuméralos de mayor a menoros de mayor a menor..a no dudes en pedirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0d17ee-9f65-42af-8586-1d7bb8077f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librerias cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Librerias a utilizar, por defecto ya vienen instaladas en el entorno \"pip install git jupyterlab numpy pandas plotly\"\n",
    "#! pip install pandasgui # para mejor visualizacion de los df\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from pandasgui import show\n",
    "print(\"librerias cargadas correctamente\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0968f5-3674-4eac-b106-d67d1ea30571",
   "metadata": {},
   "source": [
    "1. En la inspección visual del archivo, se detectaron separadores \"|\", y debido a su tamaño, se cargarán únicamente 5000 filas para revisar una parte del mismo. Esto nos permitirá visualizar rápidamente el número de columnas y los tipos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5402333-99f3-43d8-b441-7da4f2965b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ANIO             5000 non-null   int64  \n",
      " 1   MES              5000 non-null   int64  \n",
      " 2   CLIENTE          5000 non-null   int64  \n",
      " 3   ESTADO           5000 non-null   object \n",
      " 4   INGRESO          4918 non-null   float64\n",
      " 5   MORAS            5000 non-null   int64  \n",
      " 6   SEXO             5000 non-null   object \n",
      " 7   ESTADOCIVIL      5000 non-null   object \n",
      " 8   FECHANACIMIENTO  5000 non-null   object \n",
      " 9   MARCACIONES      5000 non-null   int64  \n",
      " 10  CONTACTOS        5000 non-null   int64  \n",
      " 11  M1               5000 non-null   int64  \n",
      " 12  C1               5000 non-null   int64  \n",
      " 13  M2               5000 non-null   int64  \n",
      " 14  C2               5000 non-null   int64  \n",
      " 15  M3               5000 non-null   int64  \n",
      " 16  C3               5000 non-null   int64  \n",
      " 17  ANTIGUEDAD       5000 non-null   int64  \n",
      " 18  EDAD             5000 non-null   int64  \n",
      " 19  HORARIO          5000 non-null   object \n",
      " 20  TARGET           5000 non-null   int64  \n",
      "dtypes: float64(1), int64(15), object(5)\n",
      "memory usage: 820.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0xf600c0f820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datos_internos/20210513_Challenge_AA.csv\", sep=\"|\", nrows=5000)\n",
    "\n",
    "print(df.info())\n",
    "show(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23b9ded-33a5-4adf-8f6a-30acfe871897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los horarios para clasificacion son ['MEDIODIA', 'TARDE', 'NOCHE', 'MANANA']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Los horarios para clasificacion son {list(df['HORARIO'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe700259-f59b-4f67-a3b5-04ebdfaebeb9",
   "metadata": {},
   "source": [
    "2 y 3. Para manejar eficientemente grandes volúmenes de datos, los datos del archivo .csv se cargan por partes utilizando el iterador chunksize, lo que permite procesarlos de manera incremental. A continuación, se utiliza un ciclo for para iterar sobre los horarios y se aplica el filtro correspondiente a cada uno de ellos, creando así un dataframe más reducido para cada horario. Luego, estos dataframes se anexan a sus respectivos archivos .csv. Este enfoque facilita el análisis específico para cada horario en particular y permite trabajar con los datos de manera más eficiente.o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daec5048-1ea2-4b0e-b939-4dbf8912c74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avance estimado: 98.0%\n"
     ]
    }
   ],
   "source": [
    "class CargadorCSV:\n",
    "    \"\"\"Clase para carga de archivos con formato .csv\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Constructor de la clase. Recibe la ruta del archivo.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "    \n",
    "    def visualizar_avance(self, bytes_avance, bytes_completo):\n",
    "        \"\"\"Visualiza el avance de la carga del archivo en porcentaje.\"\"\"\n",
    "        avance = min(round(bytes_avance / bytes_completo, 2) * 100, 100)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Avance estimado: {avance}%\")\n",
    "    \n",
    "    def crear_csv_por_horarios(self, chunk_size=100000, sep=\"|\"):\n",
    "        \"\"\"Crea archivos CSV separados por horarios a partir del archivo original.\"\"\"\n",
    "        try:\n",
    "            bytes_completo = os.path.getsize(self.file_path)\n",
    "            encabezado = True\n",
    "            horarios = ['MEDIODIA', 'TARDE', 'NOCHE', 'MANANA']\n",
    "            \n",
    "            for chunk in pd.read_csv(self.file_path, sep=sep, chunksize=chunk_size):\n",
    "                bytes_avance = 0\n",
    "                \n",
    "                if encabezado:\n",
    "                    for clasificador_horario in horarios:\n",
    "                        df_filtered = chunk.loc[chunk[\"HORARIO\"] == clasificador_horario].drop(\"HORARIO\", axis=1)\n",
    "                        file_name = f\"{self.file_path[:-4]}_{clasificador_horario}.csv\"\n",
    "                        df_filtered.to_csv(file_name, index=False)\n",
    "                        bytes_avance += os.path.getsize(file_name)\n",
    "                    encabezado = False\n",
    "                else:\n",
    "                    for clasificador_horario in horarios:\n",
    "                        df_filtered = chunk.loc[chunk[\"HORARIO\"] == clasificador_horario].drop(\"HORARIO\", axis=1)\n",
    "                        file_name = f\"{self.file_path[:-4]}_{clasificador_horario}.csv\"\n",
    "                        df_filtered.to_csv(file_name, mode='a', index=False, header=False)\n",
    "                        bytes_avance += os.path.getsize(file_name)\n",
    "                \n",
    "                self.visualizar_avance(bytes_avance, bytes_completo)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Proceso terminado\")\n",
    "        except Exception as error:\n",
    "            print(\"Ocurrió un error:\", error)\n",
    "\n",
    "# Leer el archivo .csv original y guardar el archivo por partes según los horarios\n",
    "cargador = CargadorCSV(\"..\\\\datos_internos\\\\20210513_Challenge_AA.csv\") \n",
    "cargador.crear_csv_por_horarios()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f97264-9279-4747-80b8-f029a6352e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c973e922-d86d-4784-b97a-3b5de3ff8760",
   "metadata": {},
   "source": [
    "10. Elaborar al menos cinco nuevas variables que de acuerdo a los resultados estadísticos posean buen poder predictivo con respecto a la variable objetivo. Explicar la construcción de las variables.s11\n",
    "11. Preprara un conjunto de entrenamiento y validación para realizar las determinaciones\r\n",
    "correspondientes. Justirfica el porcentaje usado para cada conjun12.\r\n",
    "12. Elrabora al menos tres propuestas de modelos de clasificación con las variables de tu\r\n",
    "preferencia. Justifica las propues3as.\n",
    "13. Sobre las propuestas realizadas, realiza la valoración de las métricas correspondientes\r\n",
    "sobre las muestras de entrenamiento y validación. Selecciona un modelo ganador.\r\n",
    "Justifica el uso de las métricas utilizadas y la selección del modelo que pref4eres.\r\n",
    "14. Explica cómo visualizas la implementación del modelo ganador, este podrá ser un punto\r\n",
    "a considerar dentro de tu modelo pr5ferido.\r\n",
    "15. Prepara un informe ejecutivo que detalle cada uno de los puntos de esta rúbrica, desde\r\n",
    "la carga hasta la presentación de resultados y su implementación. El entregable de este\r\n",
    "challenge será un archivo con el código y el reporte ejecutivo en formato PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d4ea4-adbf-4112-b3a6-7a4f16ea1708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
