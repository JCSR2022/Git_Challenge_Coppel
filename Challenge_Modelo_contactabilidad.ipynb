{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cd4583-45f1-446a-989f-c63856f2de3f",
   "metadata": {},
   "source": [
    "# Challenge Analítica Avanzada e Inteligencia Artificial\n",
    "## Centro de Investigación Coppel\n",
    "\n",
    "### Elaborado por: Jhonathan Santacana\n",
    "\n",
    "### Problema UNO\n",
    "\n",
    "El objetivo de este problema es desarrollar un modelo de contactabilidad que asocie una probabilidad de contacto a cada cliente en función de ciertos segmentos horarios. Para resolver este problema, se utilizará el archivo 20210513_Challenge_AA.csv, que contiene información sociodemográfica y transaccional de los clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736e789-57be-453d-98cf-214b530f9646",
   "metadata": {},
   "source": [
    "\r",
    "## A análisis preliminar y proceso ETL:\r\n",
    "\r\n",
    "1. Revisar Metadata: Revisa las características del archivo, como el formato, el tipo de datos, los tamaños y las columnas.\r\n",
    "\r\n",
    "2. Cargar los datos del archivo .csv: Realiza la carga de los datos del archivo .csv en el entorno de trabajo.\r\n",
    "\r\n",
    "3. Seleccionar horario, realizar el filtro y trabajar con un dataframe más pequeño: Selecciona un horario específico, aplica el filtro correspondiente y trabaja con un dataframe más reducido.\r\n",
    "\r\n",
    "4. Indicar las dimensiones del nue, Indica el número de filas y columnas en el nuevo archivo, así como los nombres de las variables y una descripción general de los datos.\r\n",
    "\r\n",
    "5. Obtener el número de observaciones, valores perdidos . valores NA.\r\n",
    "\r\n",
    "6. Calcular estadí, icas: Calcula medidas estadísticas básicas como el promedio, los percentiles, las desviaciones estándar, los valores mínimos y máximos, y la mediana.\r\n",
    "\r\n",
    "7. Elaborar un programa para crear un gráfico que proporcione una visión gene. al de los datos.\r\n",
    "\r\n",
    "8. Elaborar un programa para crear un gráfico de barras que muestre la frecuencia de las categ y das der los datos: Diseña un programa que genere un gráfico de barras que muestre la frecuencia de las categorías de las variables continuas.\r\n",
    "\r\n",
    "9. Realizar un análisis de corrrelaciones: Analiza las correlaciones entre las variables para identificar las que sean linealmente dependientes.\r\n",
    "\r\n",
    "10. Establecer un criterio para determinar los factores influyentes con respeirto al objetivo: Define un criterio, como el valor de Information Value o el peso de la evidencia (Weight of Evidence), para determinar los factores influyentes en relación con la varirable objetivo. Enuméralos de mayor a menor según ses, no dudes en pedirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba0806c-c053-4d8f-a7ae-c272c6e37434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0d17ee-9f65-42af-8586-1d7bb8077f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librerias cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Librerias a utilizar, por defecto ya vienen instaladas en el entorno \"pip install git jupyterlab numpy pandas plotly\"\n",
    "#! pip install pandasgui # para mejor visualizacion de los df\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from pandasgui import show\n",
    "print(\"librerias cargadas correctamente\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0968f5-3674-4eac-b106-d67d1ea30571",
   "metadata": {},
   "source": [
    "1. En la inspección visual del archivo, se detectaron separadores \"|\", y debido a su tamaño, se cargarán únicamente 5000 filas para revisar una parte del mismo. Esto nos permitirá visualizar rápidamente el número de columnas y los tipos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5402333-99f3-43d8-b441-7da4f2965b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ANIO             5000 non-null   int64  \n",
      " 1   MES              5000 non-null   int64  \n",
      " 2   CLIENTE          5000 non-null   int64  \n",
      " 3   ESTADO           5000 non-null   object \n",
      " 4   INGRESO          4918 non-null   float64\n",
      " 5   MORAS            5000 non-null   int64  \n",
      " 6   SEXO             5000 non-null   object \n",
      " 7   ESTADOCIVIL      5000 non-null   object \n",
      " 8   FECHANACIMIENTO  5000 non-null   object \n",
      " 9   MARCACIONES      5000 non-null   int64  \n",
      " 10  CONTACTOS        5000 non-null   int64  \n",
      " 11  M1               5000 non-null   int64  \n",
      " 12  C1               5000 non-null   int64  \n",
      " 13  M2               5000 non-null   int64  \n",
      " 14  C2               5000 non-null   int64  \n",
      " 15  M3               5000 non-null   int64  \n",
      " 16  C3               5000 non-null   int64  \n",
      " 17  ANTIGUEDAD       5000 non-null   int64  \n",
      " 18  EDAD             5000 non-null   int64  \n",
      " 19  HORARIO          5000 non-null   object \n",
      " 20  TARGET           5000 non-null   int64  \n",
      "dtypes: float64(1), int64(15), object(5)\n",
      "memory usage: 820.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0xf600c0f820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datos_internos/20210513_Challenge_AA.csv\", sep=\"|\", nrows=5000)\n",
    "\n",
    "print(df.info())\n",
    "show(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23b9ded-33a5-4adf-8f6a-30acfe871897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los horarios para clasificacion son ['MEDIODIA', 'TARDE', 'NOCHE', 'MANANA']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Los horarios para clasificacion son {list(df['HORARIO'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe700259-f59b-4f67-a3b5-04ebdfaebeb9",
   "metadata": {},
   "source": [
    "2 y 3. Para manejar eficientemente grandes volúmenes de datos, los datos del archivo .csv se cargan por partes utilizando el iterador chunksize, lo que permite procesarlos de manera incremental. A continuación, se utiliza un ciclo for para iterar sobre los horarios y se aplica el filtro correspondiente a cada uno de ellos, creando así un dataframe más reducido para cada horario. Luego, estos dataframes se anexan a sus respectivos archivos .csv. Este enfoque facilita el análisis específico para cada horario en particular y permite trabajar con los datos de manera más eficiente.o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daec5048-1ea2-4b0e-b939-4dbf8912c74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creacion de archivos por horarios sin problemas\n"
     ]
    }
   ],
   "source": [
    "def Creacion_csv_Horarios(file_path, chunk_size=100000, sep=\"|\"):\n",
    "    try:\n",
    "        # visualizador de proceso\n",
    "        en_proceso = \"#\"\n",
    "        bytes_completo = os.path.getsize(file_path)\n",
    "        bytes_avance = 0\n",
    "        \n",
    "        # Generar un iterador para leer el archivo CSV en partes, por defecto 1M de filas a la vez.\n",
    "        reader = pd.read_csv(file_path, sep=sep, chunksize=chunk_size)\n",
    "        \n",
    "        encabezado = True\n",
    "        horarios = ['MEDIODIA', 'TARDE', 'NOCHE', 'MANANA']\n",
    "        for chunk in reader:\n",
    "            # Visualizador de en proceso\n",
    "            print(f\"Avance estimado: {round(bytes_avance/bytes_completo,2)*100}%  {en_proceso}\")\n",
    "            bytes_avance = 0\n",
    "            if len(en_proceso) >= 40:\n",
    "                en_proceso = \"#\"\n",
    "            else:\n",
    "                en_proceso += \"#\"\n",
    "                \n",
    "            if encabezado:\n",
    "                for Clasificador_Horario in horarios:\n",
    "                    # Filtrar los datos según el horario\n",
    "                    df_filtered = chunk.loc[chunk[\"HORARIO\"] == Clasificador_Horario].drop(\"HORARIO\", axis=1)\n",
    "                    # Guardar cada parte en un archivo separado\n",
    "                    df_filtered.to_csv(f\"{file_path[:-4]}_{Clasificador_Horario}.csv\", index=False)\n",
    "                    bytes_avance += os.path.getsize(f\"{file_path[:-4]}_{Clasificador_Horario}.csv\")\n",
    "                encabezado = False\n",
    "            else:\n",
    "                for Clasificador_Horario in horarios:\n",
    "                    df_filtered = chunk.loc[chunk[\"HORARIO\"] == Clasificador_Horario].drop(\"HORARIO\", axis=1)\n",
    "                    # Agregar los datos al archivo existente sin escribir los encabezados nuevamente\n",
    "                    df_filtered.to_csv(f\"{file_path[:-4]}_{Clasificador_Horario}.csv\", mode='a', index=False, header=False) \n",
    "                    bytes_avance += os.path.getsize(f\"{file_path[:-4]}_{Clasificador_Horario}.csv\")\n",
    "                    \n",
    "            # Borrar la salida anterior /Visualizador de en proceso\n",
    "            clear_output(wait=True)\n",
    "                    \n",
    "    except Exception as error:\n",
    "        # Manejar el error y mostrar un mensaje informativo\n",
    "        print(\"Ocurrió un error:\", error)\n",
    "\n",
    "# Leer el archivo .csv original y guardar el archivo por partes según los horarios\n",
    "Creacion_csv_Horarios(\"datos_internos/20210513_Challenge_AA.csv\")\n",
    "print(\"creacion de archivos por horarios sin problemas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3f9b28-7097-4455-b730-ef7cd34886a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo1 ocupa 4008203183 bytes y el archivo2 1048178420  bytes, es un 26.0%.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta del archivo\n",
    "ruta_archivo1 = \"datos_internos/20210513_Challenge_AA.csv\"\n",
    "ruta_archivo2 = \"datos_internos/20210513_Challenge_AA.csv_MEDIODIA.csv\"\n",
    "# Obtener el tamaño del archivo en bytes\n",
    "tamaño_bytes1 = os.path.getsize(ruta_archivo1)\n",
    "tamaño_bytes2 = os.path.getsize(ruta_archivo2)\n",
    "\n",
    "print(f\"El archivo1 ocupa {tamaño_bytes1} bytes y el archivo2 {tamaño_bytes2}  bytes, es un {round(tamaño_bytes2/tamaño_bytes1,2)*100}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973e922-d86d-4784-b97a-3b5de3ff8760",
   "metadata": {},
   "source": [
    "10. Con base en los resultados de los puntos anteriores, elabora al menos cinco nuevas\r\n",
    "variables que de acuerdo a los resultados estadísticos posean buen poder predictivo con\r\n",
    "respecto a la variable objetivo. Explica la construcción de las variables.\r\n",
    "11. Prepara un conjunto de entrenamiento y validación para realizar las determinaciones\r\n",
    "correspondientes. Justifica el porcentaje usado para cada conjunto.\r\n",
    "12. Elabora al menos tres propuestas de modelos de clasificación con las variables de tu\r\n",
    "preferencia. Justifica las propuestas.\n",
    "13. Sobre las propuestas realizadas, realiza la valoración de las métricas correspondientes\r\n",
    "sobre las muestras de entrenamiento y validación. Selecciona un modelo ganador.\r\n",
    "Justifica el uso de las métricas utilizadas y la selección del modelo que prefieres.\r\n",
    "14. Explica cómo visualizas la implementación del modelo ganador, este podrá ser un punto\r\n",
    "a considerar dentro de tu modelo preferido.\r\n",
    "15. Prepara un informe ejecutivo que detalle cada uno de los puntos de esta rúbrica, desde\r\n",
    "la carga hasta la presentación de resultados y su implementación. El entregable de este\r\n",
    "challenge será un archivo con el código y el reporte ejecutivo en formato PDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
